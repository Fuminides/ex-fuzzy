{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../ex_fuzzy/')\n",
    "sys.path.append('../../ex_fuzzy/')\n",
    "\n",
    "import numpy as np\n",
    "import ex_fuzzy.rules as rules\n",
    "import ex_fuzzy.eval_rules as evr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ex_fuzzy.fuzzy_sets as fs\n",
    "import ex_fuzzy.evolutionary_fit as GA\n",
    "import ex_fuzzy.utils as  utils\n",
    "import ex_fuzzy.eval_tools as eval_tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon =  [0, 10E-3, 50E-3, 10E-2, 50E-2]\n",
    "\n",
    "def new_loss(ruleBase: rules.RuleBase, X:np.array, y:np.array, tolerance:float, alpha:float=0.99, beta:float=0.0125, gamma:float=0.0125) -> float:\n",
    "\n",
    "        '''\n",
    "        Fitness function for the optimization problem.\n",
    "        :param ruleBase: RuleBase object\n",
    "        :param X: array of train samples. X shape = (n_samples, n_features)\n",
    "        :param y: array of train labels. y shape = (n_samples,)\n",
    "        :param tolerance: float. Tolerance for the size evaluation.\n",
    "        :return: float. Fitness value.\n",
    "        '''\n",
    "        def subloss(ruleBase1, X1, y1, epsilon_val):\n",
    "\n",
    "            X1 = X1 + epsilon_val * np.random.uniform(-1, 1, X1.shape)\n",
    "            ev_object = evr.evalRuleBase(ruleBase1, X1, y1)\n",
    "            ev_object.add_rule_weights()\n",
    "\n",
    "            score_acc = ev_object.classification_eval()\n",
    "            score_size = ev_object.effective_rulesize_eval(tolerance)\n",
    "            beta = 1 - alpha\n",
    "\n",
    "            score = score_acc * alpha + score_size * beta\n",
    "        \n",
    "            return score\n",
    "        \n",
    "        epsilon_list =  [0, 10E-3, 50E-3, 10E-2, 50E-2]\n",
    "        weights = np.array([1 / len(epsilon_list)] * len(epsilon_list))**2\n",
    "        weights = weights / np.sum(weights)\n",
    "\n",
    "        score_pondered = 0\n",
    "        for epsilon, weight in zip(epsilon_list, weights):\n",
    "            score = subloss(ruleBase, X, y, epsilon)\n",
    "            score_pondered += score * weight\n",
    "        \n",
    "        return score_pondered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 50\n",
    "n_pop = 30\n",
    "nRules = 4\n",
    "nAnts = 4\n",
    "vl = 3\n",
    "tolerance = 0.0001\n",
    "fz_type_studied = fs.FUZZY_SETS.t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "precomputed_partitions = utils.construct_partitions(X, fz_type_studied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard loss experiments\n",
    "fl_classifier = GA.BaseFuzzyRulesClassifier(nRules=nRules, linguistic_variables=precomputed_partitions, nAnts=nAnts,\n",
    "                                            n_linguist_variables=vl, fuzzy_type=fz_type_studied, verbose=False, tolerance=tolerance)\n",
    "fl_classifier.fit(X_train, y_train, n_gen=n_gen, pop_size=n_pop)\n",
    "\n",
    "eval_tools.eval_fuzzy_model(fl_classifier, X_train, y_train, X_test, y_test, \n",
    "                        plot_rules=False, print_rules=True, plot_partitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New loss experiments: add different noise levels and then chooses the configuration that performed better in average\n",
    "og_accs = []\n",
    "for eps in epsilon:\n",
    "    X1 = X_test + eps * np.random.uniform(-1, 1, X_test.shape)\n",
    "    og_accs.append(np.mean(np.equal(fl_classifier.predict(X1), y_test)))\n",
    "\n",
    "\n",
    "fl_classifier = GA.BaseFuzzyRulesClassifier(nRules=nRules, linguistic_variables=precomputed_partitions, nAnts=nAnts,\n",
    "                                            n_linguist_variables=vl, fuzzy_type=fz_type_studied, verbose=False, tolerance=tolerance)\n",
    "fl_classifier.customized_loss(new_loss)\n",
    "fl_classifier.fit(X_train, y_train, n_gen=n_gen, pop_size=n_pop)\n",
    "\n",
    "eval_tools.eval_fuzzy_model(fl_classifier, X_train, y_train, X_test, y_test, \n",
    "                        plot_rules=False, print_rules=True, plot_partitions=False)\n",
    "\n",
    "\n",
    "accs = []\n",
    "for eps in epsilon:\n",
    "    X1 = X_test + eps * np.random.uniform(-1, 1, X_test.shape)\n",
    "    accs.append(np.mean(np.equal(fl_classifier.predict(X1), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epsilon, og_accs)\n",
    "plt.plot(epsilon, accs)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['Original Fitness', 'Epsilon Fitness'])\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epsilon')\n",
    "plt.savefig('iris_epsilon_t2.pdf')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
